{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U bitsandbytes accelerate\n!pip install torch transformers llmlingua\n!pip install datasets==2.21.0 huggingface-hub==0.34.0\n!git clone https://github.com/ilatims-b/LLMLingua.git","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\nimport json\nimport os","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#if dataset is longbench\n\n# Initialize data list\ndata = []\n\n# Set the number of samples to load from each dataset(for trial)\nNUM_SAMPLES = 1 \n#not including chineses, coding, answer classification, passage count dataset for now\n\n#datasets = ['narrativeqa', 'qasper', 'multifieldqa_en', 'hotpotqa', '2wikimqa', 'musique', 'gov_report', 'qmsum', 'multi_news', 'triviaqa', 'samsum', 'passage_retrieval_en']\n#for dry run only doing one, my api keys go boom\ndatasets=['multifieldqa_en']\nfor dataset_ in datasets:\n    data_ = load_dataset('THUDM/LongBench', dataset_, split='test')\n    \n\n    for idx, instance in enumerate(data_):\n        if idx >= NUM_SAMPLES:\n            break\n            \n        temp = {}\n        temp[\"dataset\"] = dataset_\n        temp[\"idx\"] = idx\n        temp[\"prompt\"] = instance['context'] + '\\n' + instance['input']  # Added newline between context and input\n        temp[\"answer\"] = instance['answers']\n        temp[\"length\"] = instance['length']\n        data.append(temp)\n\nos.makedirs(\"/kaggle/working/dataset\", exist_ok=True)\nwith open(\"/kaggle/working/dataset/longbench_1.json\", \"w\") as f:\n    json.dump(data, f, indent=4)\n#for trial i took first sample from nultifiedqna, it has only 813 tokens nearly","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nos.chdir('/kaggle/working/LLMLingua/experiments/llmlingua2/data_collection')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install openai==0.28","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#wanted to test from here but doesnt work because i had made openai account more than 3 months back, altho i did not use free trial credits, the acc is old so it does not allow\n#also they use azure, and did not have api key parge args, added that\n#generating compressed prompts from gpt4 for data annotation\n!python compress.py --load_origin_from /kaggle/working/dataset/longbench_1.json \\\n--chunk_size 512 \\\n--compressor gpt4 \\\n--model_name gpt-4o-mini \\\n--api_key \"yourapikey\"\\\n--save_path /kaggle/working/dataset/longbench_1_compressed.json","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#train data annotations\n!python label_word.py \\\n--load_prompt_from /kaggle/working/dataset/longbench_1_compressed.json \\\n--window_size 400 \\\n--save_path /kaggle/working/dataset/longbench_1_labelled.json \\","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#train data filtering, they have defined various metrics in paper\n!python filter.py \\\n--load_path /kaggle/working/dataset/longbench_1_labelled.pt\\\n--save_path /kaggle/working/dataset/longbench_1_filtered.pt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#i have added quantization, int4, int8, float16. but for training float16 is the best we should go for. 8bit and 4bit will give errors in optimizer and loss propagation\n#training on token classification using AutoModelForTokenClassification\n#xlm-roberta is not gated, but if we choose to work with another model, which is gated, add hugging face login\n!python train_roberta.py \\\n    --data_path /kaggle/input/your-dataset/train.pt \\\n    --eval_data_path /kaggle/input/your-dataset/val.pt \\\n    --save_path /kaggle/working/roberta_custom \\\n    --epochs 3 \\\n    --lr 3e-5 \\\n    --quantization float16 \\\n    --batch_size 16\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}